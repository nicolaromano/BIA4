{"cells":[{"cell_type":"markdown","metadata":{"id":"73B0TnJB90Sv"},"source":["# Image classification using convolutional neural networks\n","\n","## Introduction - the dataset\n","\n","Image classification has historically been one of the most challenging tasks in computer vision.\n","Convolutional neural networks (CNN) have allowed an unprecedented improvement in the accuracy of image classification.\n","\n","For this workshop we will use a modified version of the [ISIC 2020 Challenge dataset](https://challenge2020.isic-archive.com/). The original version of this dataset contains 33126 images benign and malignant skin lesions from over 2000 patients. The dataset is particularly challenging to work with (well, it's from a challenge, after all!) because of the very imbalanced training dataset, which contains only less than 600 images of malignant lesions.\n","\n","To simplify matters, and allow you to run this in a reasonable time frame, I have created a balanced version of the dataset, with 584 benign and 584 malignant images. Images in the original dataset are quite large (some are up to 4000 x 6000 pixels) and of different size; for simplicity I have resized them to 500 x 500 which should be sufficient for this workshop.\n","\n","Finally, note that all of the images used in this workshop come from the training set of the challenge. This is so that we have the ground truth for each image (which is obviously unavailable for the test set in the original data)."]},{"cell_type":"markdown","metadata":{"id":"H7I0Nfw8UZlx"},"source":["## Learning objectives\n","\n","At the end of this workshop you should be able to\n","\n","- Create a CNN classifier using Keras\n","- Use regularization to avoid overfitting\n","- Use data augmentation to avoid overfitting and improve accuracy"]},{"cell_type":"markdown","metadata":{"id":"BZxriDM190S3"},"source":["We start by importing our _usual_ libraries, such as keras, matplotlib numpy and pandas."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3068,"status":"ok","timestamp":1637858483187,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"NfTjPdeuQzX4"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import keras"]},{"cell_type":"markdown","metadata":{"id":"_dN8BSkx90S7"},"source":["Make sure you have the `ISIC2020_Small_metadata.csv` and `ISIC2020_Small.zip` files in the same directory as this notebook. Unzip the `ISIC2020_Small.zip` into a folder called \"ISIC2020_Small\" in the same directory as this notebook.\n","\n","The `ISIC2020_Small_metadata.csv` file contains information about all the images in the dataset. Let's open it and see what we find.\n","\n","Use the `value_counts` function to count the number of images in each class (benign vs malignant). \n","\n","How many are coming from men and how many from women?\n","\n","<details>\n","<summary style=\"cursor: pointer;\">Click here to reveal a hint.</summary>\n","Try using\n","\n","<code>\n","metadata['column_name'].value_counts()\n","</code>\n","\n","You can even pass a list of columns instead of a single string!\n","</details>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":688,"status":"ok","timestamp":1637858498158,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"NPxWGX0C90S-","outputId":"6a035b60-bd95-4052-8562-371f8576411a"},"outputs":[],"source":["image_dir = 'ISIC2020_Small/'\n","metadata = pd.read_csv('ISIC2020_Small_metadata.csv')\n","\n","# Print the metadata and the summary counts\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Cp5xkU0N90TG"},"source":["Because this is a very small dataset, it will easily fit into memory, so we could read all images.\n","\n","This can quickly become unmanageable for larger datasets, though, but luckily Keras has a built-in function to help with this.\n","\n","We are going to use the [keras.preprocessing.image_dataset_from_directory](https://keras.io/api/preprocessing/image/) function to create an image generator that will pull images when needed.\n","\n","The function can infer labels directly from the subdirectory names, which makes life a lot easier!\n","\n","We can also provide a batch size, which is the number of images we want to load at once. We can set it to 64, which should be easy enough to handle, but you might want to experiment with that.\n","\n","Note that we call the same function twice, once for the training set and once for the validation set. We use the `validation_split` parameter to split the dataset into training and validation sets (80% and 20%, respectively) and, **very importantly**, we set the `seed` parameter to the same number (you can use any number you like) to ensure that the same images are used for training and validation in both cases! This also ensures reproducibility."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3245,"status":"ok","timestamp":1637858507213,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"Z5R_7s69RExx","outputId":"9df6953d-cbb3-4e2a-8d6f-283de3a1f0e1"},"outputs":[],"source":["from keras.utils import image_dataset_from_directory\n","\n","training_dataset = image_dataset_from_directory(\n","    image_dir, \n","    labels=\"inferred\",   \n","    batch_size = 64,\n","    subset='training',\n","    validation_split=0.2,\n","    seed=12345)\n","\n","test_dataset = image_dataset_from_directory(\n","    image_dir,\n","    labels=\"inferred\",\n","    batch_size = 64,\n","    subset='validation',\n","    validation_split=0.2,\n","    seed=12345) "]},{"cell_type":"markdown","metadata":{"id":"OPhymdI090TN"},"source":["We can now use the `take` method of the generator to load some images for display.\n","We can pass 1 to `take` to get a single batch of images, then iterate through them.\n","\n","`take` returns a TensorFlow dataset, which is an iterable object, so we can use a for loop to iterate through it.\n","\n","Alternatively using\n","\n","`next(iter(training_dataset))` will return the next batch of (images, labels) from the dataset.\n","\n","Note that the images are returned as TensorFlow tensors, which are not directly displayable (but are very efficient for training!). We can use the `numpy()` method to convert them to numpy arrays, which can be displayed using `matplotlib`.\n","\n","<details>\n","<summary style=\"cursor: pointer;\">Click here to reveal a hint.</summary>\n","Try using\n","\n","```\n","# Note this returns *the whole batch*\n","for images, labels in training_dataset.take(1): \n","    for im in images:\n","        ...\n","    <display images>\n","\n","```\n","\n","You can even pass a list of columns instead of a single string!\n","</details>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"elapsed":3325,"status":"ok","timestamp":1637858606371,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"ySfoOekCRHYl","outputId":"798548b5-ae0c-4525-b07d-a7ce557cbb4f"},"outputs":[],"source":["# Display the first 9 images\n","# Your code here"]},{"cell_type":"markdown","metadata":{"id":"SfRKtBQP90TR"},"source":["Ok, we have our images and labels. Let's create a model!\n","\n","Create a convolutional neural network (CNN) model with the following architecture:\n","\n","- 3 modules of 3x3 convolutional layers with 32, 64, and 128 filters respectively followed by a max pooling layer\n","- 2 dense layers with 512 and 64 units respectively\n","- a final dense layer with 1 unit for the output\n","\n","Use ReLU activation for all layers except the last one where you can use a sigmoid.\n","\n","Compile the model. \n","\n","**What optimizer and loss function do you want to use?**\n","**What metrics do you want to calculate?**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1637859090816,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"6zxZhoPlQ-q0","outputId":"524aff4c-4965-4f98-cd47-a59a6d462c34"},"outputs":[],"source":["model = keras.models.Sequential()\n","\n","# Build your model here\n","\n","print(model.summary())"]},{"cell_type":"markdown","metadata":{"id":"8MswL5R2uSGK"},"source":["We can now proceed to train our model. We will train for 50 epochs, with a batch size of 128. \n","\n","So, every epoch all of the training images are used to train the network, 128 images at a time.\n","\n","Note that we use our test set for validation, so we have no proper validation set for this example.\n","\n","The `train` function returns the model's history, which contains information about the accuracy over training. This is important to check how well the model is working.\n","\n","Since this is a fairly time-consuming process, you might want to run this on Google Colab, using a GPU."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5218,"status":"ok","timestamp":1637859780087,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"dCmgXTxoRIqO","outputId":"de595480-1196-4aa4-946e-f32bca4b141a"},"outputs":[],"source":["batch_size = 128\n","epochs_num = 50\n","\n","res = model.fit(\n","    # your code here\n","    )"]},{"cell_type":"markdown","metadata":{"id":"bGd1z38KBNwb"},"source":["We can now plot loss and accuracy for our model.\n","\n","**What can you tell from the plot?** (you might want to zoom in on the y axis)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1637862500210,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"M56TrKIVRRa_","outputId":"f5359f69-654b-473a-db28-ea22110ad35c"},"outputs":[],"source":["# Plot loss and validation for training and validation sets"]},{"cell_type":"markdown","metadata":{},"source":["Optionally, you can save the model for later use, so you don't have to train it again."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save(\"mymodels/melanoma_model_01\")\n","# You can load back the model at any time using\n","# model = keras.models.load_model('mymodels/melanoma_model_01)"]},{"cell_type":"markdown","metadata":{"id":"QtH4xqPXfNGM"},"source":["We have slightly more than 75% accuracy, which is OK, but can definitely be improved!\n","\n","What do you think is happening here?\n","\n","<details>\n","<summary style=\"cursor: pointer;\">Click here to reveal the solution.</summary>\n","Our model seems to be **overfitting**! \n","**How do we tell that?**\n","\n","1. The loss continues to decrease, but validation loss goes up\n","2. Training accuracy goes up, but validation reaches a plateau\n","</details>"]},{"cell_type":"markdown","metadata":{},"source":["\n","There are several things that we can improve.\n","\n","1. We can regularize the model by adding **dropout**. This would be especially important for the dense layers.\n","\n","2. We can add regularization (e.g. **L2 regularization**) to the model\n","\n","3. Part of the issue is that the training set is somewhat limited. This is partly because I have given you a only amount of a  of images, however keep in mind that having a very large amount of image data is not always a given, actually it is quite uncommon! \n","As we saw in the lectures, we can use **data augmentation** to increase the size of our dataset.\n","\n","Let's train a new model exactly in the same way, but adding dropout and regularization."]},{"cell_type":"markdown","metadata":{"id":"A0mKuimZGI7_"},"source":["1. Add 40% Dropout layers after each Dense layer (not the last one, obviously!)\n","2. Add L2 regularization to the Conv2D layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1637861768547,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"13D6uiCsF6YP","outputId":"63c601c8-3511-4ee0-da07-d39fafb2ddf3"},"outputs":[],"source":["model2 = keras.models.Sequential()\n","\n","#  Build a regularized version of the model here\n","\n","print(model2.summary())"]},{"cell_type":"markdown","metadata":{"id":"nXhY74KDJ18d"},"source":["As before, repeat the training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431403,"status":"ok","timestamp":1637862205661,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"W-_aVjhMH4vD","outputId":"e39aa0bb-8711-41b1-abf3-7e5e77b35844"},"outputs":[],"source":["batch_size = 128\n","epochs_num = 50\n","\n","res2 = model2.fit(\n","    # Your code here\n","    ) \n","\n","# Save model\n","model2.save(\"mymodels/melanoma_02\")\n","# You can also save the history!\n","np.save('mymodels/melanoma_02_history.npy', res2.history)"]},{"cell_type":"markdown","metadata":{"id":"ZM0luj3mKdGz"},"source":["Plot the loss and accuracy for the regularised model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":895,"status":"ok","timestamp":1637862229039,"user":{"displayName":"Nicola Romanò","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9q00QQPkf3B4FVjp9F55bIGxDvz911r5j0RazMiw=s64","userId":"17270478908509198483"},"user_tz":0},"id":"zMvVhWPUKgMO","outputId":"e4433fb9-d1b8-48c8-f72e-ffb9dbe9dab8"},"outputs":[],"source":["# Plot loss and validation for training and validation sets"]},{"cell_type":"markdown","metadata":{},"source":["Now, that's much better!\n","\n","The model is now regularised, so it does not overfit anymore (or not as badly). You can play with the hyperparameters to see if you can improve the model even further.\n","\n","Finally, we can use the model to predict the class of some images. We are going to use the validation set for this, although it would be better to have a separate test set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","images, labels = next(iter(test_dataset))\n","\n","predictions = ______________\n","\n","conf_matr = ______________\n","\n","print(conf_matr)"]},{"cell_type":"markdown","metadata":{"id":"U_E6xoRygHW3"},"source":["How did your model do? Can you improve it further?\n","\n","\n","And that is the end of worshop 6! Hope you enjoyed it and keep (deep) learning!"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CNN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}
