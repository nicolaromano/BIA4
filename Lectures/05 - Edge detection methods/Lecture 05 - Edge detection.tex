\documentclass[9pt, aspectratio=169]{beamer}
\usepackage{FiraSans}
\usetheme[subsectionpage=progressbar]{metropolis}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{xcolor}
\usepackage[T1]{fontenc} 
\usepackage[skins]{tcolorbox}
\author{Nicola Roman\`o - nicola.romano@ed.ac.uk}
\title{Lecture 5 - Edge detection}
\setlength{\fboxsep}{0pt}
\setbeamertemplate{caption}{\raggedright\insertcaption\par}
\setbeamertemplate {footline}{\begin{scriptsize}\hfill\insertframenumber ~of \inserttotalframenumber\kern1em\vskip5pt\end{scriptsize}}

%\setbeamercovered{transparent} 
%\setbeamertemplate{navigation symbols}{} 

\titlegraphic{\centering \includegraphics[scale=.5]{instituteLogo.png}}
\date{}

\begin{document}

\newtcolorbox{codebox}{enhanced,
    top=2pt,
    left=2pt,
    right=2pt,
    bottom=2pt,
    boxrule=0pt,
    leftrule=5pt,
    sharp corners,
    colback=gray!20,
    colframe=blue!60!black}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}
    {Learning objectives}
    \begin{columns}
        \begin{column}{0.8\textwidth}
            \begin{itemize}
                \item Explain the use of image derivatives for edge detection
                \item Describe various edge detection algorithms
                \item Implement them in Python
            \end{itemize}
        \end{column}
        \begin{column}{0.2\textwidth}
            \includegraphics[angle=-30, origin=tr, width=1.5\textwidth]{lightbulb.png}
        \end{column}
    \end{columns}
\end{frame}

\section{Edge detection - introduction}

\begin{frame}
    {Edge detection problem}
    An edge is an area where the brightness of an image changes more or less gradually.

    Detecting edges is useful e.g. to find objects in a scene, determine which pixels belong to which objects, and measure their properties.
    \begin{figure}
        \includegraphics[width=\textwidth]{monarch_sobel.png}
        \caption{\footnotesize{\color{gray}{Monarch butterfly - CC-BY-SA 2.0 Ted @ Flickr}\color{black}}}
    \end{figure}
\end{frame}

\begin{frame}
    {How to detect an edge?}
    \includegraphics[width=\textwidth]{line_intensity.png}
    Consider the vertical edges. We can see a change in the intensity of pixels as we move from black to white and vice versa. \textbf{Can you think of a way to detect these edges?}
\end{frame}

\subsection{First derivatives approaches}

\begin{frame}
    {We can use derivatives!}
    \includegraphics[width=\textwidth]{intensity_derivative.png}
    Edges will correspond to minima and maxima of the derivative of the intensity!
\end{frame}

\begin{frame}
    {Image derivatives}
    With a 2D image, we can find the x and y derivatives of the image intensity \huge$(\frac{\partial I}{\partial x} $\normalsize and \huge$\frac{\partial I}{\partial y})$.
    \normalsize
    We can combine the derivatives in a vector, called the \textbf{gradient}:
    \huge{
        $$\nabla I = \begin{bmatrix}\frac{\partial I}{\partial x}, \frac{\partial I}{\partial y}\end{bmatrix}$$}
    \pause
    \normalsize
    The gradient is a vector with:
    \begin{itemize}
        \item Direction perpendicular to the edge
              \Large{
                  $$\theta = \arctan\left(\frac{\partial I}{\partial x} \mathbin{/} \frac{\partial I}{\partial y}\right)$$}
              \pause
              \normalsize
        \item Length (\textbf{gradient magnitude}) proportional to the intensity change
              \Large{
                  $$\lvert\lvert\nabla I\rvert\rvert = \sqrt{\left(\frac{\partial I}{\partial x}\right)^2 + \left(\frac{\partial I}{\partial y}\right)^2}$$}
    \end{itemize}
\end{frame}

\begin{frame}
    {Example of gradient vectors}
    \centering
    \includegraphics[width=.7\textwidth]{monarch_gradient.png}
\end{frame}

\begin{frame}
    {Calculating a discrete derivative}
    How to calculate a discrete derivative?

    Remember the definition of a derivative for a continuous function $f(x)$:
    $$f'(x) = \frac{df}{dx} = \lim_{\Delta x \rightarrow 0} \frac{f(x) - f(x - \Delta x)}{\Delta x}$$

    \pause
    Our image is not continuous, as it is made up of discrete pixels so the minimum $\Delta x$ value is 1 (a single pixel).

    \pause
    The discrete derivative is given by:
    \Large{
        $$\frac{dI}{dx} = \frac{I(x) - I(x-1)}{1} = I(x) - I(x-1)$$}
\end{frame}

\begin{frame}
    {Calculating the discrete derivative - variations}
    We can choose to calculate the discrete derivative in three different ways

    \Large
    \begin{itemize}
        \item \textbf{Forward difference}: $I(x) - I(x+1)$
        \item \textbf{Backward difference}: $I(x) - I(x-1)$
        \item \textbf{Central difference}: $I(x+1) - I(x-1)$
    \end{itemize}

    \pause
    These can be easily calculated using \textbf{convolution}!

    \begin{itemize}
        \item \textbf{Forward difference}: $\begin{bmatrix}1&-1\end{bmatrix}$
        \item \textbf{Backward difference}: $\begin{bmatrix}-1&1\end{bmatrix}$
        \item \textbf{Central difference}: $\begin{bmatrix}-1&0&1\end{bmatrix}$
    \end{itemize}
\end{frame}

\begin{frame}
    {Discrete derivative - example}
    Let's calculate the discrete derivative of this 1D image using central difference

    \begin{tikzpicture}[ampersand replacement=\&]
        \matrix [matrix of nodes, nodes={draw, minimum height=2em, minimum width=2em, anchor=center}, column sep=0] at (0, 0) {10 \& 16 \& 22 \& 36 \& 40 \& 11 \& 17 \& 23 \& 37 \& 41\\};
    \end{tikzpicture}

    \pause
    Convolving with the kernel

    \begin{tikzpicture}[ampersand replacement=\&]
        \matrix [matrix of nodes, nodes={draw, minimum height=2em, minimum width=2em, anchor=center}, column sep=0] at (0, 0) {-1 \& 0 \& 1\\};
    \end{tikzpicture}

    We obtain the following

    \begin{tikzpicture}[ampersand replacement=\&]
        \matrix [matrix of nodes, nodes={draw, minimum height=2em, minimum width=2em, anchor=center}, column sep=0] at (0, 0) {0 \& 12 \& 20 \& 18 \& -25 \& -23 \& 12 \& 20 \& 18 \& 0\\};
    \end{tikzpicture}
\end{frame}

\begin{frame}
    {Derivatives of an image by convolution}
    We can apply these convolution kernels to an image as well.

    $$K_x = \begin{bmatrix}-1&0&1\end{bmatrix} \qquad K_y = \begin{bmatrix}-1\\0\\1\end{bmatrix}$$

    \only<1>{
        \includegraphics[width=.8\textwidth]{monarch_derivatives.png}
    }
    \only<2>{
        \includegraphics[width=\textwidth]{monarch_derivatives_and_gradient.png}
    }
\end{frame}

\begin{frame}
    {The problem with noise}
    Derivatives are very sensitive to noise. Smoothing the function beforehand helps

    \centering
    \includegraphics[width=.7\textwidth]{derivative_noise.png}
\end{frame}

\begin{frame}
    {Smoothed 1st derivative kernels}
    We can smooth the derivative kernels by averaging nearby pixels.

    These are called \textbf{Prewitt} kernels.

    $$K_x = \begin{bmatrix}-1&0&1\\-1&0&1\\-1&0&1\end{bmatrix} \qquad K_y = \begin{bmatrix}-1&-1&-1\\0&0&0\\1&1&1\end{bmatrix}$$

    Alternatively the \textbf{Sobel} kernels can be used:

    $$K_x = \begin{bmatrix}-1&0&1\\-2&0&2\\-1&0&1\end{bmatrix} \qquad K_y = \begin{bmatrix}-1&-2&-1\\0&0&0\\1&2&1\end{bmatrix}$$
\end{frame}

\begin{frame}
    {Your turn!}
    Consider the following image. \textbf{What do you expect to obtain and why} after convolution with the Prewitt kernels?\\
    Apply the convolution (you can easily do that by hand); \textbf{do the results match} your prediction?

    $$\begin{bmatrix}0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   \\
            0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   \\
            0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   \\
            50  & 50  & 50  & 50  & 50  & 50  & 50  & 50  \\
            100 & 100 & 100 & 100 & 100 & 100 & 100 & 100 \\
            100 & 100 & 100 & 100 & 100 & 100 & 100 & 100 \\
            50  & 50  & 50  & 50  & 50  & 50  & 50  & 50  \\
            0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   \\
            0   & 0   & 0   & 0   & 0   & 0   & 0   & 0
        \end{bmatrix}$$
\end{frame}

\begin{frame}
    {Edge detection - Prewitt and Sobel}
    Having applied either the Prewitt or Sobel kernels to the image we can now detect edges.

    Simply threshold the gradient magnitude of the image to define which pixels are edges.

    \centering
    \includegraphics[width=.9\textwidth]{monarch_prewitt.png}
\end{frame}

\begin{frame}
    {Edge detection in Scikit Image}
    \begin{columns}
        \begin{column}{.6\textwidth}
            \begin{codebox}
                \texttt{from skimage.filters import prewitt, sobel\\
                    from skimage.io import imread\\
                    \\
                    img = imread("butterfly.jpg")\\
                    im\_prewitt = prewitt(img)\\
                    im\_sobel = sobel(img)\\
                    \pause
                    \\
                    fig, ax = plt.subplots(2, 1, figsize=(5, 10))\\
                    ax[0].imshow(im\_prewitt > 0.08, cmap="gray")\\
                    ax[0].set\_title("Prewitt", fontsize=25)\\
                    ax[1].imshow(im\_sobel > 0.08, cmap="gray")\\
                    ax[1].set\_title("Sobel", fontsize=25)\\
                    for a in ax:\\
                    a.axis("off")\\
                    plt.show()}
            \end{codebox}
        \end{column}
        \begin{column}{.4\textwidth}
            \includegraphics[width=.7\textwidth]{monarch_prewitt_sobel.png}
        \end{column}
    \end{columns}
\end{frame}

% \subsection{Marr-Hildreth}

% \begin{frame}
%     {Marr-Hildreth detector (Laplacian of Gaussian)}

%     The Marr-Hildreth detector finds edges by first smoothing the image using a Gaussian filter, then finding the Laplacian of the smoothed image.

%     \pause

%     The Laplacian ($\Delta$ or $\nabla^2$) of the image is the sum of the second partial derivatives of the image.

%     $$\nabla^2(I) = \frac{\partial^2 I}{\partial x^2} + \frac{\partial^2 I}{\partial y^2}$$

%     Technically, this is defined as the divergence of the gradient of the image. 

% \end{frame}

\subsection{Second derivative approaches}

\begin{frame}
    {Second derivative approaches}
    We can also use second derivatives to detect edges.
    \only<2>{Edges correspond to \textbf{zero-crossings} of the second derivative.}

    \centering
    \includegraphics[width=.7\textwidth]{intensity_derivative.png}
    \pause
    \centering
    \includegraphics[width=.3\textwidth]{intensity_second_derivative.png}
\end{frame}

\begin{frame}
    {The Laplacian}
    We can combine the second derivatives of the image using the \textbf{Laplacian} operator.
    \Large{
    $$\nabla^2 I(x,y) = \frac{\partial^2{I}}{\partial{x^2}}+ \frac{\partial^2{I}}{\partial{y^2}}$$
    }
    \normalsize
    The zero-crossing in the Laplacian are the \textbf{edges} of the image.

    The Laplacian can be approximated by convolving with the kernel:

    $$\begin{bmatrix}
            0 & 1  & 0 \\
            1 & -4 & 1 \\
            0 & 1  & 0
        \end{bmatrix}$$

    \textbf{Can you guess how we got to that?}
\end{frame}

\begin{frame}
    {Approximating the Laplacian}

    We calculated the first derivative of the image using the backward difference as:

    \Large
    $$\frac{\partial I}{\partial x} = I'_x = I_x - I_{x-1} \qquad \frac{\partial I}{\partial y} = I'_y = I_y - I_{y-1}$$

    \pause
    \normalsize
    Similarly, for the second derivative we can write:

    \Large
    $$\frac{\partial^2 I}{\partial x^2} = I"_x = I'_x - I'_{x-1} = [I_x - I_{x-1}] - [I_{x-1} - I_{x-2}] = I_x - 2I_{x-1} + I_{x-2}$$
    \pause
    \normalsize
    Applying the same reasoning to the y derivative, we obtain these kernels:

    \centering

    $\begin{bmatrix}
            1 & -2 & 1
        \end{bmatrix}
        \qquad
        \begin{bmatrix}
            1  \\
            -2 \\
            1
        \end{bmatrix}
    $
    which sum to  $\begin{bmatrix}
            0 & 1  & 0 \\
            1 & -4 & 1 \\
            0 & 1  & 0
        \end{bmatrix}$
\end{frame}

\begin{frame}
    {The Laplacian is very sensitive to noise}
    \begin{figure}
        \includegraphics[width=.5\textwidth]{laplacian_zero_crossing_no_smooth.png}
        \caption{\small{\color{gray}{Zero crossing of the Laplacian of our butterfly image}\color{black}}}
        \pause
        \textit{Challenge: can you try and reproduce this image?\\ Hint: use \texttt{ skimage.filters.edges.convolve} to apply the Laplacian kernel, then look at the sign of the result using the \texttt{np.sign} function... and think how you can define a zero-crossing!}
    \end{figure}
\end{frame}

\begin{frame}
    {Laplacian vs Sobel/Prewitt operators}
    \begin{itemize}
        \item Both operators are sensitive to noise (Laplacian is more sensitive).
        \item The Laplacian uses a single kernel, while the Sobel and Prewitt operators use two kernels.
        \item This means that the Laplacian loses orientation information.
        \item The Laplacian is an \textbf{isotropic filter}, meaning that it is invariant to the direction of the gradient (i.e. it performs well in all edge directions).
        \item Generally, Laplacian gives better edge localization
    \end{itemize}

\end{frame}
\begin{frame}
    {Smoothing the Laplacian}
    When using the Laplacian, most often we first smooth the image using a Gaussian filter, then convolve with the Laplacian kernel.

    This can be done in one step since:

    \Large
    $$\nabla^2(G_\sigma * I) = \nabla^2(G_\sigma) * I$$
    \pause
    \normalsize
    This is called the Laplacian of Gaussian (\textbf{LoG}) filter.

    \begin{figure}
        \centering
        \includegraphics[width=.45\textwidth]{gaussian_and_laplacian_2D.png}
        \includegraphics[width=.45\textwidth]{gaussian_and_laplacian_3D.png}
    \end{figure}
\end{frame}

\begin{frame}
    {Approximation of the LoG}
    The Laplacian of a Gaussian function is given by:

    \Large
    $$LoG(x,y) = -\frac{1}{\pi \sigma^4}[1-\frac{x^2+y^2}{2\sigma^2}]\cdot e^{-\frac{x^2+y^2}{2\sigma^2}}$$

    \normalsize
    \centering
    (no need to remember this formula, I certainly don't!)\\
    \pause

    This can be approximated by a LoG kernel. For example, for $\sigma = 1.4$ we can approximate LoG by:

    \begin{columns}
        \begin{column}{.4\textwidth}
            \small
            $\begin{bmatrix}0 & 0 & 1 & 2   & 2   & 2   & 1 & 0 & 0 \\
                    0 & 1 & 3 & 5   & 5   & 5   & 3 & 1 & 0 \\
                    1 & 3 & 5 & 3   & 0   & 3   & 5 & 3 & 1 \\
                    2 & 5 & 3 & -12 & -23 & -12 & 3 & 5 & 2 \\
                    2 & 5 & 0 & -23 & -40 & -23 & 0 & 5 & 2 \\
                    2 & 5 & 3 & -12 & -23 & -12 & 3 & 5 & 2 \\
                    1 & 3 & 5 & 3   & 0   & 3   & 5 & 3 & 1 \\
                    0 & 1 & 3 & 5   & 5   & 5   & 3 & 1 & 0 \\
                    0 & 0 & 1 & 2   & 2   & 2   & 1 & 0 & 0\end{bmatrix}$
        \end{column}
        \begin{column}{.3\textwidth}
            \centering
            \includegraphics[width=.9\textwidth]{LoG kernel.png}
        \end{column}
        \pause
        \begin{column}{.4\textwidth}
            \includegraphics[width=.8\textwidth]{laplacian_of_gaussian_zero_crossing.png}
        \end{column}
    \end{columns}
\end{frame}

\subsection {Canny}
\begin{frame}
    {The Canny edge detector}
    The Canny edge detector is a more advanced algorithm to detect edges.

    It involves five steps

    \begin{enumerate}
        \item Apply a Gaussian filter to the image to smooth out noise
        \item Calculate the gradient magnitude (e.g. using a Sobel filter)
        \item Non-maximum suppression
        \item Double thresholding
        \item Edge tracking by hysteresis
    \end{enumerate}
\end{frame}

\begin{frame}
    {The Canny edge detector - step 1 and 2 - smoothing and gradient}
    We start by convolving the image with a Gaussian kernel to smooth noise.

    We then calculate the gradient magnitude and angle using the Sobel kernels.
    \centering
    \includegraphics[width=\textwidth]{canny_step1-2.png}
\end{frame}

\begin{frame}
    {The Canny edge detector - step 3 - non-maximum suppression}
    Non-maximum suppression allows us to thin the edges by only keeping the pixels with the largest gradient magnitude in the edge.

    For each pixel, we take the neighbouring pixels in the direction of the gradients, and we keep only the pixels with the largest gradient magnitude.

    \begin{columns}
        \begin{column}{.33\textwidth}
            \begin{tikzpicture}[scale=0.25]
                \draw [fill=black] (-5, -5) rectangle (9, 9);
                \draw [fill=white, color=white] (0, 0) rectangle (1, 2) rectangle (2, 3) rectangle (4, 4) rectangle (5, 6) rectangle (4, 7);
                \draw [fill=white, color=white] (3, 4) rectangle (4, 5);
                \draw [fill=gray, color=gray] (-1, -1) rectangle (2, 0) rectangle (1, 2);
                \draw [fill=gray, color=gray] (2, 2) rectangle (5, 3);
                \draw [fill=black!30!white, color=black!30!white] (4, 3) rectangle (6, 4) rectangle (5, 7);
                \draw [fill=white, color=white] (2, 2) rectangle (3, 3);
                \draw [->, color=red, very thick] (4.5, 3.5) -- (7.5, 0.5);
                \draw [color=red, dashed] (3, 2) rectangle (6, 5);
            \end{tikzpicture}
        \end{column}
        \begin{column}{.33\textwidth}
            \begin{tikzpicture}[scale=1.2]
                \draw [fill=black] (0, 0) rectangle (3, 3);
                \draw [fill=white, color=white] (0, 1) rectangle (1, 2);
                \draw [fill=black!30!white, color=black!30!white] (1, 1) rectangle (3, 3);
                \draw [fill=white, color=white] (0, 2) rectangle (2, 3);
                \draw [fill=gray, color=gray] (0, 0) rectangle (2, 1);
                \draw [color=red, dashed] (0, 3) rectangle (1, 2) rectangle (2, 1) rectangle (3, 0);
            \end{tikzpicture}
        \end{column}
        \pause
        \begin{column}{.33\textwidth}
            \begin{tikzpicture}[scale=1.2]
                \draw [fill=black] (0, 0) rectangle (3, 3);
                \draw [fill=white, color=white] (0, 1) rectangle (1, 2);
                \draw [fill=black!30!white, color=black!30!white] (1, 1) rectangle (3, 3);
                \draw [fill=white, color=white] (0, 2) rectangle (2, 3);
                \draw [fill=gray, color=gray] (0, 0) rectangle (2, 1);
                \draw [fill=black, color=black] (1, 1) rectangle (2, 2);
                \draw [color=red, dashed] (0, 3) rectangle (1, 2) rectangle (2, 1) rectangle (3, 0);
            \end{tikzpicture}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    {The Canny edge detector - step 4 - double thresholding}
    The next step is to set two arbitrary thresholds, one for the weak edges and one for the strong edges.

    \begin{itemize}
        \item \textbf{Strong edges} are those with gradient magnitude above the high threshold.
        \item \textbf{Weak edges} are those with gradient magnitude between the low and high threshold.
        \item Edges with gradient magnitude below the low threshold are suppressed (set to 0).
    \end{itemize}
\end{frame}

\begin{frame}
    {The Canny edge detector - step 5 - hysteresis}
    We need to decide what to do with weak edges.
    We keep those weak edges that are near a strong edge, and discard the others.

    \vspace{2em}

    \begin{columns}
        \begin{column}{.33\textwidth}
            \begin{tikzpicture}
                \draw [fill=black] (0, 0) rectangle (3, 3);
                \draw [fill=white, color=white] (0, 1) rectangle (2, 2);
                \draw [fill=gray, color=gray] (0, 0) rectangle (1, 1);
                \draw [color=red, dashed] (1, 1) rectangle (2, 2);
                \node [align=center, text width=2cm] at (1.5, -1) {Strong edge, keep};
            \end{tikzpicture}
        \end{column}
        \begin{column}{.33\textwidth}
            \begin{tikzpicture}
                \draw [fill=black] (0, 0) rectangle (3, 3);
                \draw [fill=white, color=white] (0, 1) rectangle (1, 2);
                \draw [fill=gray, color=gray] (1, 1) rectangle (2, 2);
                \draw [color=red, dashed] (1, 1) rectangle (2, 2);
                \node [align=center, text width=4cm] at (1.5, -1) {Weak edge near strong, mark as strong};
            \end{tikzpicture}
        \end{column}
        \begin{column}{.33\textwidth}
            \begin{tikzpicture}
                \draw [fill=black] (0, 0) rectangle (3, 3);
                \draw [fill=gray, color=gray] (0, 0) rectangle (2, 2);
                \draw [color=red, dashed] (1, 1) rectangle (2, 2);
                \node [align=center, text width=2cm] at (1.5, -1) {Weak edge, remove};
            \end{tikzpicture}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    {The Canny edge detector - The final result!}
    \centering
    \includegraphics[width=\textwidth]{canny_step1-2.png}

    \includegraphics[width=.75\textwidth]{canny_step3-5.png}

    This is implemented in the \href{https://scikit-image.org/docs/dev/api/skimage.feature.html\#skimage.feature.canny}{\underline{skimage.feature.canny}} function.
    Try it by yourself and change the parameters to see what happens!

    Want to read more? The original 1986 paper from Canny is attached (lots of maths in there!).
\end{frame}

\begin{frame}
    {Summary}
    \begin{itemize}
        \item Edge detection is a valuable tool for image processing.
        \item We have covered some of the most common algorithms for edge detection, which can be used as an early step in more complex analysis pipelines.
              \begin{itemize}
                  \item Prewitt and Sobel, based on the first derivative of the image.
                  \item The Laplacian of Gaussian (LoG) based on the second derivative.
                  \item The Canny edge detector, still based on first derivatives, but with a more complex approach.
              \end{itemize}
        \item In the next lecture we will look at other algorithms to detect specific features in images.
    \end{itemize}



\end{frame}
\end{document}